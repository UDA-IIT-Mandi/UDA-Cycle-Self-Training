namespace(root='./data/dcase', data='DCASE', source='source', target='target', temperature=2.0, alpha=1.9, trade_off=0.08, trade_off1=0.5, trade_off3=0.5, threshold=0.97, rho=0.5, batch_size=3, lr=0.0005, lr_gamma=0.001, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=50, early=45, iters_per_epoch=1000, val_interval=10, print_freq=100, seed=None, per_class_eval=False, log='logs/dcase', phase='test', sample_rate=32000, clip_length=10, num_cls=10, device=device(type='cuda'))
/home/teaching/miniconda3/lib/python3.12/site-packages/torch/functional.py:730: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.
Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at /pytorch/aten/src/ATen/native/SpectralOps.cpp:875.)
  return _VF.stft(  # type: ignore[attr-defined]
/home/teaching/miniconda3/lib/python3.12/site-packages/hear21passt/models/preprocess.py:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
x torch.Size([3, 1, 128, 1000])
/home/teaching/miniconda3/lib/python3.12/site-packages/hear21passt/models/passt.py:304: UserWarning: Input image size (128*1000) doesn't match model (128*998).
  warnings.warn(f"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).")
self.norm(x) torch.Size([3, 768, 12, 99])
 patch_embed :  torch.Size([3, 768, 12, 99])
 self.time_new_pos_embed.shape torch.Size([1, 768, 1, 99])
 self.freq_new_pos_embed.shape torch.Size([1, 768, 12, 1])
X flattened torch.Size([3, 1188, 768])
 self.new_pos_embed.shape torch.Size([1, 2, 768])
 self.cls_tokens.shape torch.Size([3, 1, 768])
 self.dist_token.shape torch.Size([3, 1, 768])
 final sequence x torch.Size([3, 1190, 768])
 after 12 atten blocks x torch.Size([3, 1190, 768])
forward_features torch.Size([3, 768])
head torch.Size([3, 527])
Test: [  0/110]	Time  1.334 ( 1.334)	Loss 7.9470e-01 (7.9470e-01)	Acc@1  66.67 ( 66.67)	Acc@5 100.00 (100.00)
Test: [100/110]	Time  0.089 ( 0.101)	Loss 1.7735e+00 (6.1348e-01)	Acc@1  33.33 ( 76.90)	Acc@5 100.00 (100.00)
 * Acc@1 76.970 Acc@5 100.000

Device-specific results:
Device a: 76.97% (254/330)
76.96969576748934
Test: [  0/880]	Time  0.967 ( 0.967)	Loss 6.3080e-01 (6.3080e-01)	Acc@1  66.67 ( 66.67)	Acc@5 100.00 (100.00)
Test: [100/880]	Time  0.089 ( 0.098)	Loss 1.2292e+00 (1.1568e+00)	Acc@1  33.33 ( 56.77)	Acc@5 100.00 ( 99.01)
Test: [200/880]	Time  0.090 ( 0.094)	Loss 7.3186e-01 (1.1764e+00)	Acc@1  66.67 ( 55.56)	Acc@5 100.00 ( 98.18)
Test: [300/880]	Time  0.092 ( 0.093)	Loss 5.6464e-01 (1.1813e+00)	Acc@1 100.00 ( 55.37)	Acc@5 100.00 ( 98.12)
Test: [400/880]	Time  0.092 ( 0.092)	Loss 1.7552e+00 (1.1953e+00)	Acc@1   0.00 ( 55.69)	Acc@5 100.00 ( 97.84)
Test: [500/880]	Time  0.093 ( 0.093)	Loss 2.3983e+00 (1.1824e+00)	Acc@1  33.33 ( 56.42)	Acc@5  66.67 ( 97.94)
Test: [600/880]	Time  0.093 ( 0.093)	Loss 1.7106e+00 (1.1854e+00)	Acc@1  33.33 ( 56.24)	Acc@5 100.00 ( 97.78)
Test: [700/880]	Time  0.094 ( 0.093)	Loss 2.1466e-01 (1.1812e+00)	Acc@1 100.00 ( 56.44)	Acc@5 100.00 ( 97.96)
Test: [800/880]	Time  0.095 ( 0.093)	Loss 4.6872e-01 (1.1877e+00)	Acc@1 100.00 ( 55.85)	Acc@5 100.00 ( 98.13)
 * Acc@1 56.179 Acc@5 97.915

Device-specific results:
Device b: 62.61% (206/329)
Device s3: 54.85% (181/330)
Device s1: 46.36% (153/330)
Device s2: 49.09% (162/330)
Device c: 74.77% (246/329)
Device s4: 53.03% (175/330)
Device s6: 50.91% (168/330)
Device s5: 57.88% (191/330)
56.17892196487531
