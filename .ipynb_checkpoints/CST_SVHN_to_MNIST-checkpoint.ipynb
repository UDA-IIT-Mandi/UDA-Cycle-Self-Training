{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CST (Contrastive Semi-supervised Training) for SVHN → MNIST\n",
    "\n",
    "This notebook adapts the CST domain adaptation pipeline for the SVHN → MNIST scenario. All code is self-contained except for the imports from your repo; please copy the relevant functions/classes into the indicated cells."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Cell 1: Standard Library & Torch Imports ---\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import SVHN, MNIST\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Utility Imports from Your Repo\n",
    "\n",
    "Paste code for (or reimplement here):\n",
    "- ResizeImage (from your `common/vision/transforms`)\n",
    "- ForeverDataIterator, AverageMeter, ProgressMeter, accuracy, etc.\n",
    "- ImageClassifier (from `fix_utils`)\n",
    "- SAM optimizer (from `sam`)\n",
    "- rand_augment_transform\n",
    "\n",
    "If you don't have these locally, you can temporarily comment them out and use basic equivalents."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Cell 2: Paste or reimplement your local utility classes and functions here ---\n",
    "# Example: (Replace with your actual code)\n",
    "# class ResizeImage: ...\n",
    "# class ForeverDataIterator: ...\n",
    "# def accuracy(...): ...\n",
    "# class ImageClassifier(nn.Module): ...\n",
    "# class SAM(torch.optim.Optimizer): ...\n",
    "# def rand_augment_transform(...): ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: CST Loss and Training Utilities\n",
    "\n",
    "Paste your definitions for:\n",
    "- entropy\n",
    "- TsallisEntropy\n",
    "- (Optionally) any additional loss/utilities"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Cell 3: CST loss and utilities ---\n",
    "def entropy(predictions: torch.Tensor, reduction='none') -> torch.Tensor:\n",
    "    epsilon = 1e-5\n",
    "    H = -predictions * torch.log(predictions + epsilon)\n",
    "    H = H.sum(dim=1)\n",
    "    if reduction == 'mean':\n",
    "        return H.mean()\n",
    "    else:\n",
    "        return H\n",
    "\n",
    "class TsallisEntropy(nn.Module):\n",
    "    def __init__(self, temperature: float, alpha: float):\n",
    "        super(TsallisEntropy, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, logits: torch.Tensor) -> torch.Tensor:\n",
    "        N, C = logits.shape\n",
    "        pred = F.softmax(logits / self.temperature, dim=1)\n",
    "        entropy_weight = entropy(pred).detach()\n",
    "        entropy_weight = 1 + torch.exp(-entropy_weight)\n",
    "        entropy_weight = (N * entropy_weight / torch.sum(entropy_weight)).unsqueeze(dim=1)\n",
    "        sum_dim = torch.sum(pred * entropy_weight, dim=0).unsqueeze(dim=0)\n",
    "        return 1 / (self.alpha - 1) * torch.sum((1 / torch.mean(sum_dim) - torch.sum(pred ** self.alpha / sum_dim * entropy_weight, dim=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Transforms for SVHN and MNIST\n",
    "\n",
    "We need to ensure MNIST images are converted to 3 channels to match SVHN and the model. This is also where we define strong/weak augmentations for FixMatch."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Cell 4: Transforms ---\n",
    "MNIST_MEAN, MNIST_STD = (0.1307,), (0.3081,)\n",
    "SVHN_MEAN, SVHN_STD = (0.4377, 0.4438, 0.4728), (0.1980, 0.2010, 0.1970)\n",
    "\n",
    "class ToThreeChannels:\n",
    "    def __call__(self, img):\n",
    "        return img.repeat(3, 1, 1)\n",
    "\n",
    "def get_mnist_transform(crop=True):\n",
    "    normalize = T.Normalize(mean=[0.1307]*3, std=[0.3081]*3)\n",
    "    base = [\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224) if crop else T.RandomResizedCrop(224),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        ToThreeChannels(),\n",
    "        normalize\n",
    "    ]\n",
    "    return T.Compose(base)\n",
    "\n",
    "def get_svhn_transform(crop=True):\n",
    "    normalize = T.Normalize(mean=SVHN_MEAN, std=SVHN_STD)\n",
    "    base = [\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224) if crop else T.RandomResizedCrop(224),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        normalize\n",
    "    ]\n",
    "    return T.Compose(base)\n",
    "\n",
    "# If you have a rand_augment_transform, use it in the strong branch below\n",
    "class TransformFixMatch:\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        if dataset == 'mnist':\n",
    "            normalize = T.Normalize(mean=[0.1307]*3, std=[0.3081]*3)\n",
    "            to3 = ToThreeChannels()\n",
    "            weak = [T.Resize(256), T.CenterCrop(224), T.RandomHorizontalFlip(), T.ToTensor(), to3, normalize]\n",
    "            strong = weak[:-2] + [T.RandomApply([T.ColorJitter(0.4,0.4,0.4,0)], p=1.0)] # add more if needed\n",
    "            strong += [T.ToTensor(), to3, normalize]\n",
    "        else:\n",
    "            normalize = T.Normalize(mean=SVHN_MEAN, std=SVHN_STD)\n",
    "            weak = [T.Resize(256), T.CenterCrop(224), T.RandomHorizontalFlip(), T.ToTensor(), normalize]\n",
    "            strong = weak[:-2] + [T.RandomApply([T.ColorJitter(0.4,0.4,0.4,0)], p=1.0)]\n",
    "            strong += [T.ToTensor(), normalize]\n",
    "        self.weak = T.Compose(weak)\n",
    "        self.strong = T.Compose(strong)\n",
    "    def __call__(self, x):\n",
    "        weak = self.weak(x)\n",
    "        strong = self.strong(x)\n",
    "        return weak, strong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Data Preparation\n",
    "\n",
    "Download and prepare SVHN (source, labeled) and MNIST (target, unlabeled/val/test) datasets."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Cell 5: Data preparation ---\n",
    "root = './data'  # change if desired\n",
    "batch_size = 28\n",
    "num_workers = 2\n",
    "\n",
    "train_transform = get_svhn_transform(crop=True)\n",
    "unlabeled_transform = TransformFixMatch('mnist')\n",
    "val_transform = get_mnist_transform(crop=True)\n",
    "\n",
    "train_source_dataset = SVHN(root=root, split='train', download=True, transform=train_transform)\n",
    "train_source_loader = DataLoader(train_source_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "\n",
    "train_target_dataset = MNIST(root=root, train=True, download=True, transform=unlabeled_transform)\n",
    "train_target_loader = DataLoader(train_target_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "\n",
    "val_dataset = MNIST(root=root, train=False, download=True, transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Optionally: Wrap loaders in ForeverDataIterator if you have it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Model and Optimizer\n",
    "\n",
    "Instantiate your model (e.g., ResNet-18 with attached bottleneck and classifier head for 10 classes) and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Cell 6: Model & Optimizer ---\n",
    "# Paste or implement your model and bottleneck logic here, or use torchvision.models\n",
    "import torchvision.models as models\n",
    "\n",
    "# Assume ImageClassifier is your custom class with backbone & bottleneck\n",
    "# backbone = models.resnet18(pretrained=True)\n",
    "# classifier = ImageClassifier(backbone, num_classes=10, bottleneck_dim=256).to(device)\n",
    "\n",
    "# For demonstration, use a simple model (replace this with your ImageClassifier):\n",
    "backbone = models.resnet18(pretrained=True)\n",
    "backbone.fc = nn.Linear(backbone.fc.in_features, 10)\n",
    "classifier = backbone.to(device)\n",
    "\n",
    "# Setup optimizer and scheduler\n",
    "lr = 0.005\n",
    "optimizer = SGD(classifier.parameters(), lr=lr, momentum=0.9, weight_decay=1e-3)\n",
    "lr_scheduler = LambdaLR(optimizer, lambda x: lr * (1. + 0.001 * float(x)) ** (-0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Training and Validation Functions\n",
    "\n",
    "Paste your `train`, `validate`, and any other functions needed for the loop."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Cell 7: Training and validation loops ---\n",
    "# Paste your 'train' and 'validate' functions here from run_cst.py\n",
    "# Example:\n",
    "def train(...):\n",
    "    pass\n",
    "\n",
    "def validate(...):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Experiment Setup and Execution\n",
    "\n",
    "Set hyperparameters, run the training loop, and validate."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Cell 8: Run experiment ---\n",
    "epochs = 20\n",
    "early = 20\n",
    "\n",
    "# Example loop (adapt as needed for your CST training logic)\n",
    "for epoch in range(epochs):\n",
    "    # train(train_source_iter, train_target_iter, classifier, ts_loss, optimizer, lr_scheduler, epoch, args)\n",
    "    # acc = validate(val_loader, classifier, args)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} ... (train/validate logic here)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Visualization and Analysis (Optional)\n",
    "\n",
    "Add t-SNE, confusion matrix, or accuracy plots here."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Cell 9: Visualization ---\n",
    "# Example: Plot accuracy or t-SNE if available\n",
    "# import matplotlib.pyplot as plt\n",
    "# ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}